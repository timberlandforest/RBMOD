{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_0j8W6d8pBs"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# __Recovery Boiler Models__ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Problema de Negocio__: Optimización del % de Reducción en la Caldera Recuperadora\n",
    "\n",
    "En el proceso de producción de celulosa, la eficiencia de la caldera recuperadora es un factor crítico tanto desde el punto de vista económico como ambiental. El **% de reducción** de la caldera, que mide la transformación de compuestos inorgánicos como sulfato de sodio (Na₂SO₄) a sulfuro de sodio (Na₂S), es un indicador clave de rendimiento. Sin embargo, mantener un alto % de reducción es un desafío debido a las variaciones en las condiciones de operación, la calidad del licor negro y otros factores del proceso. \n",
    "\n",
    "Actualmente, la planta carece de una herramienta predictiva que permita anticipar y optimizar el comportamiento del **% de reducción** en tiempo real. Esto limita la capacidad de la planta para:\n",
    "\n",
    "1. **Maximizar la recuperación de químicos:** Incrementar la eficiencia del ciclo de recuperación química para reducir la dependencia de reactivos externos.\n",
    "2. **Optimizar el uso de energía:** Mejorar la generación de vapor y la autosuficiencia energética de la planta.\n",
    "3. **Reducir costos operativos:** Minimizar el gasto en reactivos químicos y el mantenimiento no planificado de la caldera.\n",
    "4. **Promover la sostenibilidad:** Reducir el impacto ambiental mediante un mejor control del proceso.\n",
    "\n",
    "### __Objetivo del Modelo de Machine Learning__\n",
    "\n",
    "Desarrollar un modelo de machine learning que prediga el **% de reducción** de la caldera recuperadora con base en datos históricos y en tiempo real de parámetros operativos como:\n",
    "\n",
    "- Composición del licor negro.\n",
    "- Temperatura.\n",
    "- Presión.\n",
    "- Flujo y otros datos relevantes.\n",
    "\n",
    "El modelo permitirá:\n",
    "\n",
    "- Identificar condiciones subóptimas y ajustar las variables operativas en tiempo real.\n",
    "- Reducir costos operativos al optimizar el uso de reactivos y energía.\n",
    "- Mejorar la sostenibilidad del proceso al maximizar la eficiencia química y energética.\n",
    "- Ofrecer una herramienta de soporte a los operadores para tomar decisiones informadas y mantener la estabilidad del ciclo químico.\n",
    "\n",
    "Este modelo se integrará como parte del sistema de monitoreo y control, ayudando a la planta a alcanzar sus objetivos de eficiencia económica y ambiental."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción de las Variables\n",
    "\n",
    "### Variables Temporales\n",
    "\n",
    "1. `datetime`: fecha y hora de cada medición.\n",
    "\n",
    "---\n",
    "\n",
    "### Variables Operativas\n",
    "\n",
    "2. `Carga [TSS/d]`: Cantidad de sólidos secos totales alimentados a la caldera.\n",
    "\n",
    "3. `Solidos a quemado [%]`: Porcentaje de sólidos secos en el licor negro hacia caldera.\n",
    "\n",
    "4. `Temperatura LN a boquillas [°C]`: Temperatura del licor negro a las boquillas de la caldera.\n",
    "\n",
    "5. `Flujo agua alimentacion [t/h]`: Cantidad de agua alimentada a la caldera.\n",
    "\n",
    "6. `Temperatura de salida vapor [°C]`: Temperatura del vapor generado a la salida de la caldera.\n",
    "\n",
    "7. `gen_vapor [ton/h]`: Generación de vapor.\n",
    "\n",
    "8. `press_hogar [kPa]`: Presión en el hogar de la caldera.\n",
    "\n",
    "---\n",
    "\n",
    "### Coeficientes de Transferencia de Calor\n",
    "\n",
    "09. `heat_coef_SH1 [kJ/m²°C]`: Coeficiente de transferencia de calor en el primer sobrecalentador.\n",
    "\n",
    "10. `heat_coef_SH2 [kJ/m²°C]`: Coeficiente de transferencia de calor en el segundo sobrecalentador.\n",
    "\n",
    "11. `heat_coef_SH3 [kJ/m²°C]`: Coeficiente de transferencia de calor en el tercer sobrecalentador.\n",
    "\n",
    "12. `heat_coef_SH4 [kJ/m²°C]`: Coeficiente de transferencia de calor en el cuarto sobrecalentador.\n",
    "\n",
    "---\n",
    "\n",
    "### Indicadores Químicos y de Reducción\n",
    "\n",
    "13. `reduction_ins [%]`: Porcentaje de reducción instantáneo medido en tiempo real.\n",
    "\n",
    "14. `alcali_lv_ins [g/L]`: Concentración de álcali en licor verde medida instantáneamente.\n",
    "\n",
    "15. `sulfidez_ins [%]`: Porcentaje de sulfidez en el licor verde medido instantáneamente.\n",
    "\n",
    "---\n",
    "\n",
    "### Contaminantes en Gases de Combustión\n",
    "\n",
    "16. `NOx [mg/Nm³]`: Concentración de óxidos de nitrógeno en los gases de combustión.\n",
    "\n",
    "17. `Material particulado [mg/Nm³]`: Concentración de partículas sólidas en los gases de combustión.\n",
    "\n",
    "18. `SO2 [mg/Nm³]`: Concentración de dióxido de azufre en los gases de combustión.\n",
    "\n",
    "19. `TRS [mg/Nm³]`: Concentración de compuestos reducidos de azufre en los gases de combustión.\n",
    "\n",
    "20. `CO [mg/Nm³]`: Concentración de monóxido de carbono en los gases de combustión.\n",
    "\n",
    "---\n",
    "\n",
    "### Indicadores de Oxígeno y Monóxido de Carbono\n",
    "\n",
    "21. `O2_cont_left [%]`: Porcentaje de oxígeno en la sección izquierda de la caldera.\n",
    "\n",
    "22. `O2_cont_center [%]`: Porcentaje de oxígeno en el centro de la caldera.\n",
    "\n",
    "23. `O2_cont_right [%]`: Porcentaje de oxígeno en la sección derecha de la caldera.\n",
    "\n",
    "24. `CO_cont_left_wall [%]`: Concentración de monóxido de carbono en la pared izquierda de la caldera.\n",
    "\n",
    "25. `CO_cont_center [%]`: Concentración de monóxido de carbono en el centro de la caldera.\n",
    "\n",
    "26. `CO_cont_right_wall [%]`: Concentración de monóxido de carbono en la pared derecha de la caldera.\n",
    "\n",
    "---\n",
    "\n",
    "### Flujo de Aire en Etapas de Combustión\n",
    "\n",
    "27. `Primario`: Flujo de aire en la etapa primaria de la combustión.\n",
    "\n",
    "28. `Secundario`: Flujo de aire en la etapa secundaria de la combustión.\n",
    "\n",
    "29. `Secundario Alto`: Flujo de aire en una subetapa secundaria más alta.\n",
    "\n",
    "30. `Terciario`: Flujo de aire en la etapa terciaria de la combustión.\n",
    "\n",
    "31. `Cuaternario`: Flujo de aire en la etapa cuaternaria de la combustión.\n",
    "\n",
    "---\n",
    "\n",
    "### Indicadores de Proceso\n",
    "\n",
    "32. `Aire de combustión/ carga de licor [Nm³/kg DS]`: Relación entre el flujo de aire y la cantidad de sólidos secos del licor negro.\n",
    "\n",
    "33. `Temperatura de gases de salida [°C]`: Temperatura de los gases que salen de la caldera.\n",
    "\n",
    "34. `Ratio flujo de vapor/ [Ton vap/kg DS]`: Relación entre el flujo de vapor generado y la cantidad de sólidos secos del licor negro.\n",
    "\n",
    "35. `Atemperacion [°C]`: Temperatura del vapor tras el proceso de atemperación.\n",
    "\n",
    "36. `T15 [°C]`: Temperatura medida en un punto específico del sistema.\n",
    "\n",
    "37. `Soiling_rate_point`: Tasa de ensuciamiento en un punto crítico del sistema.\n",
    "\n",
    "38. `Diff_Press_SC [kPa]`: Diferencia de presión en la sección de sobrecalentador.\n",
    "\n",
    "39. `Diff_Press_BG [kPa]`: Diferencia de presión en la sección del hogar de la caldera.\n",
    "\n",
    "40. `Diff_Press_ECO1 [kPa]`: Diferencia de presión en el economizador 1.\n",
    "\n",
    "41. `Diff_Press_ECO2 [kPa]`: Diferencia de presión en el economizador 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. __Exploración y Preparación de los Datos__\n",
    "\n",
    "1. **Importación de los Datos**:\n",
    "\n",
    "   - Cargar los datos del sistema en formato CSV\n",
    "\n",
    "2. **Análisis Exploratorio de Datos (EDA)**:\n",
    "\n",
    "   - Examinar la distribución de las variables.\n",
    "   - Identificar valores atípicos y faltantes.\n",
    "   - Visualizar correlaciones clave entre variables y el % de reducción.\n",
    "\n",
    "3. **Limpieza de Datos**:\n",
    "\n",
    "   - Manejar valores faltantes (imputación o eliminación según corresponda).\n",
    "   - Normalizar las variables si es necesario para el análisis.\n",
    "\n",
    "4. **Ingeniería de Características**:\n",
    "\n",
    "   - Crear nuevas variables relevantes basadas en las existentes (por ejemplo, características temporales, medias moviles, etc).\n",
    "\n",
    "5. **División del Conjunto de Datos**:\n",
    "\n",
    "   - Separar los datos en conjuntos de entrenamiento, validación y prueba para evitar problemas de overfitting (sobreajuste).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. __Modelado__\n",
    "\n",
    "1. **Selección de Modelos**:\n",
    "\n",
    "   - Probar diferentes algoritmos de machine learning, como regresión lineal, árboles de decisión, `Random Forest` o modelos basados en `Gradient Boosting`.\n",
    "\n",
    "2. **Entrenamiento del Modelo**:\n",
    "\n",
    "   - Entrenar los modelos utilizando el conjunto de datos de entrenamiento.\n",
    "   - Ajustar hiperparámetros utilizando técnicas como `Grid Search` o `Random Search`.\n",
    "\n",
    "3. **Evaluación del Modelo**:\n",
    "\n",
    "   - Medir el rendimiento de los modelos utilizando métricas como el error cuadrático medio (`RMSE`) y el coeficiente de determinación (`R²`).\n",
    "   - Validar el modelo en el conjunto de prueba para comprobar su capacidad de generalización.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. __Interpretación de Resultados__\n",
    "\n",
    "1. **Análisis de Importancia de Variables**:\n",
    "\n",
    "   - Identificar las variables más relevantes para el modelo.\n",
    "   - Realizar análisis de sensibilidad para entender cómo afectan las variables al `% de reducción`.\n",
    "\n",
    "2. **Visualización de Resultados**:\n",
    "\n",
    "   - Crear gráficos para representar los resultados del modelo.\n",
    "   - Comparar los valores predichos con los valores reales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CesuSOiw8mXe",
    "outputId": "19f32051-0c62-4a7e-ee49-70ba83d58efa"
   },
   "outputs": [],
   "source": [
    "#Importar librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "KCH_G-Rb8-Zw",
    "outputId": "81a18dba-bc7f-4dd6-bd4f-b1c399750d60"
   },
   "outputs": [],
   "source": [
    "# Cargar Datos y convertirlos en un DataFrame\n",
    "df = pd.read_csv('data_caldera.csv')\n",
    "\n",
    "# Visualizar una muestra del DataFrame\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la columna categórica basada en las condiciones\n",
    "def categorize_reduction(value):\n",
    "    if 5460 <= value < 5850:\n",
    "        return 'Low'\n",
    "    elif 5850 <= value < 6240:\n",
    "        return 'Medium'\n",
    "    elif 6240 <= value < 7424:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return None  # Opcional: Para valores fuera del rango definido\n",
    "\n",
    "df['charge_level'] = df['Carga [TSS/d]'].apply(categorize_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados\n",
    "df['charge_level'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qx2-n6vnPwd0",
    "outputId": "bc946fca-dd24-477b-d32a-b4b6cb4dcb80"
   },
   "outputs": [],
   "source": [
    "# Estructura de la base de Datos\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de la columna a procesar\n",
    "target_column = 'Carga [TSS/d]'\n",
    "\n",
    "# Calcular el IQR para la columna específica\n",
    "Q1 = df[target_column].quantile(0.25)\n",
    "Q3 = df[target_column].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Definir límites\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtrar filas que están dentro de los límites\n",
    "df_sin_outliers = df[(df[target_column] >= lower_bound) & (df[target_column] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados\n",
    "df_sin_outliers['charge_level'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "XthsSKEpPbIg",
    "outputId": "3f1f7aae-1e4b-4894-eb27-63a49613a8c5"
   },
   "outputs": [],
   "source": [
    "# Visalizar linea de tiempo para la carga de la caldera\n",
    "ssq_scatter = px.scatter(df,\n",
    "                   x='datetime',\n",
    "                   y='Carga [TSS/d]',\n",
    "                   title='Carga [TSS/d] Over Time',\n",
    "                   labels={'ts': 'Timestamp', 'Carga [TSS/d]': 'Carga [TSS/d]'})\n",
    "\n",
    "# Ajustar las dimensiones de la visualización\n",
    "ssq_scatter.update_layout(width=1000, height=600, title_font_size=20)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "ssq_scatter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visalizar linea de tiempo para la carga de la caldera\n",
    "ssq_scatter = px.scatter(df_sin_outliers,\n",
    "                   x='datetime',\n",
    "                   y='Carga [TSS/d]',\n",
    "                   title='Carga [TSS/d] Over Time',\n",
    "                   labels={'ts': 'Timestamp', 'Carga [TSS/d]': 'Carga [TSS/d]'})\n",
    "\n",
    "# Ajustar las dimensiones de la visualización\n",
    "ssq_scatter.update_layout(width=1000, height=600, title_font_size=20)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "ssq_scatter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_data = (df_sin_outliers[(df_sin_outliers['reduction_ins [%]'] > 80) & (df_sin_outliers['reduction_ins [%]'] < 100)].shape[0]/len(df_sin_outliers))\n",
    "percent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_sin_outliers[(df_sin_outliers['reduction_ins [%]'] > 80) & (df_sin_outliers['reduction_ins [%]'] < 100)]['charge_level'].value_counts(dropna=False) / len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter =  df_sin_outliers[(df_sin_outliers['reduction_ins [%]'] > 80) & (df_sin_outliers['reduction_ins [%]'] < 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un gráfico de líneas para la variable reducción\n",
    "red_scatter = px.scatter(filter,\n",
    "                   x='datetime',\n",
    "                   y='reduction_ins [%]',\n",
    "                   color = 'charge_level',\n",
    "                   title='reduction_ins [%] Over Time',\n",
    "                   labels={'ts': 'Timestamp', 'reduction_ins [%]': 'Reduction_ins [%]'})\n",
    "\n",
    "# Ajustar margenes de la visualización\n",
    "red_scatter.update_layout(width=1000, height=600, title_font_size=20)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "red_scatter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se filtraran los datos para diferentes niveles de `carga de caldera` para un rango de tiempo determinado (Posterior a PGP) y evaluaremos las correlaciónes entre variables y efectividad de algunos modelos de machine learning.\n",
    "\n",
    "Por otro lado se `eliminaran outliers`, para omitir eventos particulares que no reflejan el comportamiento ideal para la caldera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-0HNYjp4NfG",
    "outputId": "86d8ea29-7357-410e-d0b4-b5204d639bcc"
   },
   "outputs": [],
   "source": [
    "# Filtrar la data con diferentes cargas de solidos secos [ton/h]\n",
    "\n",
    "low_dc = df_sin_outliers[\n",
    "    (df_sin_outliers['datetime'] >= '2024-06-20') &\n",
    "    (df_sin_outliers['datetime'] >= '2024-09-20') &\n",
    "    (df_sin_outliers['Carga [TSS/d]'] >= 5460) &\n",
    "    (df_sin_outliers['Carga [TSS/d]'] < 5850) &\n",
    "    (df_sin_outliers['reduction_ins [%]'] > 80) &\n",
    "    (df_sin_outliers['reduction_ins [%]'] < 100)\n",
    "]\n",
    "\n",
    "medium_dc = df_sin_outliers[\n",
    "    (df_sin_outliers['datetime'] >= '2024-06-20') &\n",
    "    (df_sin_outliers['datetime'] >= '2024-09-20') &\n",
    "    (df_sin_outliers['Carga [TSS/d]'] >= 5850) &\n",
    "    (df_sin_outliers['Carga [TSS/d]'] < 6240) &\n",
    "    (df_sin_outliers['reduction_ins [%]'] > 80) &\n",
    "    (df_sin_outliers['reduction_ins [%]'] < 100)\n",
    "]\n",
    "\n",
    "high_dc = df_sin_outliers[\n",
    "    (df_sin_outliers['datetime'] >= '2024-06-20') &\n",
    "    (df_sin_outliers['datetime'] >= '2024-09-20') &\n",
    "    (df_sin_outliers['Carga [TSS/d]'] >= 6240) &\n",
    "    (df_sin_outliers['Carga [TSS/d]'] < 6800) &\n",
    "    (df_sin_outliers['reduction_ins [%]'] > 80) &\n",
    "    (df_sin_outliers['reduction_ins [%]'] < 100)\n",
    "]\n",
    "\n",
    "print(f'Tamaño low_dc: {low_dc.shape}')\n",
    "print(f'Tamaño medium_dc: {medium_dc.shape}')\n",
    "print(f'Tamaño high_dc: {high_dc.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_outliers[['Carga [TSS/d]', 'Temperatura LN a boquillas [°C]', 'sulfidez_ins [%]', 'reduction_ins [%]', 'O2_cont_center [%]']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_dc[['Carga [TSS/d]', 'Temperatura LN a boquillas [°C]', 'sulfidez_ins [%]', 'reduction_ins [%]', 'O2_cont_center [%]']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_dc[['Carga [TSS/d]', 'Temperatura LN a boquillas [°C]', 'sulfidez_ins [%]', 'reduction_ins [%]', 'O2_cont_center [%]']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_dc[['Carga [TSS/d]', 'Temperatura LN a boquillas [°C]', 'sulfidez_ins [%]', 'reduction_ins [%]', 'O2_cont_center [%]']].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean características temporales para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmLwmo9n94KV"
   },
   "outputs": [],
   "source": [
    "# Crear características temporales para cada carga de la caldera\n",
    "low_dc['month'] = pd.to_datetime(low_dc['datetime']).dt.month\n",
    "low_dc['day'] = pd.to_datetime(low_dc['datetime']).dt.day\n",
    "low_dc['hour'] = pd.to_datetime(low_dc['datetime']).dt.hour\n",
    "low_dc['minute'] = pd.to_datetime(low_dc['datetime']).dt.minute\n",
    "\n",
    "medium_dc['month'] = pd.to_datetime(medium_dc['datetime']).dt.month\n",
    "medium_dc['day'] = pd.to_datetime(medium_dc['datetime']).dt.day\n",
    "medium_dc['hour'] = pd.to_datetime(medium_dc['datetime']).dt.hour\n",
    "medium_dc['minute'] = pd.to_datetime(medium_dc['datetime']).dt.minute\n",
    "\n",
    "high_dc['month'] = pd.to_datetime(high_dc['datetime']).dt.month\n",
    "high_dc['day'] = pd.to_datetime(high_dc['datetime']).dt.day\n",
    "high_dc['hour'] = pd.to_datetime(high_dc['datetime']).dt.hour\n",
    "high_dc['minute'] = pd.to_datetime(high_dc['datetime']).dt.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previamente se realizo feature engineering por lo que se realizo una selección de las características mas importantes para entrenar y evaluar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txEroFj9zCvi"
   },
   "outputs": [],
   "source": [
    "# Características relevantes\n",
    "\n",
    "features = ['datetime', 'Carga [TSS/d]', 'Solidos a quemado [%]', 'Temperatura LN a boquillas [°C]',\n",
    "            'Flujo agua alimentacion [t/h]', 'Temperatura de salida vapor [°C]', 'gen_vapor [ton/h]',\n",
    "            'press_hogar [kPa]', 'heat_coef_SH1 [kJ/m2C]', 'heat_coef_SH2 [kJ/m2C]', 'heat_coef_SH3 [kJ/m2C]',\n",
    "            'heat_coef_SH4 [kJ/m2C]', 'reduction_ins [%]', 'alcali_lv_ins [g/L]', 'sulfidez_ins [%]',\n",
    "            'NOx [mg/Nm³]', 'Material particulado [mg/Nm³]', 'SO2 [mg/Nm³]', 'TRS [mg/Nm³]',\n",
    "            'CO [mg/Nm³]', 'O2_cont_left [%]', 'O2_cont_center [%]', 'O2_cont_right [%]', 'CO_cont_left_wall [%]',\n",
    "            'CO_cont_center [%]', 'CO_cont_right_wall [%]', 'Primario', 'Secundario', 'Secundario Alto',\n",
    "            'Terciario', 'Cuaternario', 'Aire de combustión/ carga de licor [Nm3/kg DS]', 'Temperatura de gases de salida [°C]',\n",
    "            'Ratio flujo de vapor/ [Ton vap/kg DS]', 'Atemperacion [°C]', 'T15 [°C]', 'Soiling_rate_point', 'Diff_Press_SC [kPa]',\n",
    "            'Diff_Press_BG [kPa]', 'Diff_Press_ECO1 [kPa]', 'Diff_Press_ECO2 [kPa]', 'charge_level', 'month', 'day', 'hour', 'minute']\n",
    "\n",
    "# Filtrar las características mas relevantes para cada dataframe\n",
    "low_dcf = low_dc[features]\n",
    "medium_dcf = medium_dc[features]\n",
    "high_dcf = high_dc[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a visualizar la carga de la caldera y la variable objetivo con los filtros predefinidos previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un gráfico de líneas\n",
    "fig_scatter = px.scatter(high_dcf,\n",
    "                   x='datetime',\n",
    "                   y='Carga [TSS/d]',\n",
    "                   title='Carga [TSS/d] Over Time',\n",
    "                   labels={'datetime': 'Timestamp', 'Carga [TSS/d]': 'Carga [TSS/d]'})\n",
    "\n",
    "# Mejorar la estética del gráfico\n",
    "fig_scatter.update_layout(width=1000, height=600, title_font_size=20)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig_scatter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un gráfico de líneas\n",
    "fig_scatter = px.scatter(medium_dc,\n",
    "                   x='datetime',\n",
    "                   y='reduction_ins [%]',\n",
    "                   color = 'charge_level',\n",
    "                   title='reduction_ins [%] Over Time',\n",
    "                   labels={'datetime': 'Timestamp', 'reduction_ins [%]': 'Reduction_ins [%]'})\n",
    "\n",
    "# Mejorar la estética del gráfico\n",
    "fig_scatter.update_layout(width=1000, height=600, title_font_size=20)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig_scatter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de estilo\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Crear figura y subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Histograma para 'Carga [TSS/d]'\n",
    "sns.histplot(\n",
    "    data=low_dcf,\n",
    "    x=\"Carga [TSS/d]\",\n",
    "    color=\"skyblue\",\n",
    "    kde=True,  # Agregar línea KDE\n",
    "    alpha=0.7,\n",
    "    ax=axes[0]  # Especificar el primer subplot\n",
    ")\n",
    "axes[0].set_title(\"Distribución de Carga [TSS/d]\", fontsize=14)\n",
    "axes[0].set_xlabel(\"Carga [TSS/d]\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Frecuencia\", fontsize=12)\n",
    "\n",
    "# Histograma para 'reduction_ins [%]'\n",
    "sns.histplot(\n",
    "    data=low_dcf,\n",
    "    x=\"reduction_ins [%]\",\n",
    "    color=\"red\",\n",
    "    kde=True,  # Agregar línea KDE\n",
    "    alpha=0.7,\n",
    "    ax=axes[1]  # Especificar el segundo subplot\n",
    ")\n",
    "axes[1].set_title(\"Distribución de Reduction_ins [%]\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Reduction_ins [%]\", fontsize=12)\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "# Ajustar diseño y mostrar gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de estilo\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Crear figura y subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Histograma para 'Carga [TSS/d]'\n",
    "sns.histplot(\n",
    "    data=medium_dcf,\n",
    "    x=\"Carga [TSS/d]\",\n",
    "    color=\"skyblue\",\n",
    "    kde=True,  # Agregar línea KDE\n",
    "    alpha=0.7,\n",
    "    ax=axes[0]  # Especificar el primer subplot\n",
    ")\n",
    "axes[0].set_title(\"Distribución de Carga [TSS/d]\", fontsize=14)\n",
    "axes[0].set_xlabel(\"Carga [TSS/d]\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Frecuencia\", fontsize=12)\n",
    "\n",
    "# Histograma para 'reduction_ins [%]'\n",
    "sns.histplot(\n",
    "    data=medium_dcf,\n",
    "    x=\"reduction_ins [%]\",\n",
    "    color=\"red\",\n",
    "    kde=True,  # Agregar línea KDE\n",
    "    alpha=0.7,\n",
    "    ax=axes[1]  # Especificar el segundo subplot\n",
    ")\n",
    "axes[1].set_title(\"Distribución de Reduction_ins [%]\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Reduction_ins [%]\", fontsize=12)\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "# Ajustar diseño y mostrar gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de estilo\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Crear figura y subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Histograma para 'Carga [TSS/d]'\n",
    "sns.histplot(\n",
    "    data=high_dcf,\n",
    "    x=\"Carga [TSS/d]\",\n",
    "    color=\"skyblue\",\n",
    "    kde=True,  # Agregar línea KDE\n",
    "    alpha=0.7,\n",
    "    ax=axes[0]  # Especificar el primer subplot\n",
    ")\n",
    "axes[0].set_title(\"Distribución de Carga [TSS/d]\", fontsize=14)\n",
    "axes[0].set_xlabel(\"Carga [TSS/d]\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Frecuencia\", fontsize=12)\n",
    "\n",
    "# Histograma para 'reduction_ins [%]'\n",
    "sns.histplot(\n",
    "    data=high_dcf,\n",
    "    x=\"reduction_ins [%]\",\n",
    "    color=\"red\",\n",
    "    kde=True,  # Agregar línea KDE\n",
    "    alpha=0.7,\n",
    "    ax=axes[1]  # Especificar el segundo subplot\n",
    ")\n",
    "axes[1].set_title(\"Distribución de Reduction_ins [%]\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Reduction_ins [%]\", fontsize=12)\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "# Ajustar diseño y mostrar gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los gráficos resaltan una `distribución multimodal` tanto para la `carga (TSS/d)` como para el porcentaje de reducción (`Reduction_ins`). Esto sugiere la presencia de diferentes modos de operación o configuraciones que afectan el proceso. Un análisis más profundo sobre la relación entre estas dos variables y otros parámetros operativos podría proporcionar insights clave para optimizar el sistema. También sería valioso explorar técnicas de `clustering o análisis de segmentos` para agrupar diferentes configuraciones de operación y entender su impacto en la eficiencia de la caldera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear subplots con 1 fila y 2 columnas\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[\"Carga [TSS/d]\", \"reduction_ins [%]\"])\n",
    "\n",
    "# Boxplot para 'Carga [TSS/d]'\n",
    "fig.add_trace(\n",
    "    go.Box(\n",
    "        y=medium_dcf['Carga [TSS/d]'],\n",
    "        name='Carga [TSS/d]',\n",
    "        boxpoints='all',  # Mostrar todos los puntos\n",
    "        jitter=0.3,       # Separar los puntos\n",
    "        pointpos=-1.8     # Ajustar posición de los puntos\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Boxplot para 'reduction_ins [%]'\n",
    "fig.add_trace(\n",
    "    go.Box(\n",
    "        y=medium_dcf['reduction_ins [%]'],\n",
    "        name='reduction_ins [%]',\n",
    "        boxpoints='all',  # Mostrar todos los puntos\n",
    "        jitter=0.3,       # Separar los puntos\n",
    "        pointpos=-1.8     # Ajustar posición de los puntos\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Actualizar diseño\n",
    "fig.update_layout(\n",
    "    title_text=\"Boxplots de Variables\",\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    showlegend=False  # Ocultar leyendas\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `boxplot de Carga [TSS/d]` muestra una distribución estable sin valores extremos significativos, lo que indica un control adecuado de la carga en el proceso.\n",
    "\n",
    "El `boxplot de Reduction_ins [%]` muestra variabilidad significativa con algunos valores atípicos que podrían requerir mayor atención para entender su origen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluye la columna 'datetime' antes de calcular la correlación\n",
    "df_numeric = medium_dcf.select_dtypes(include=['number'])  # Selecciona solo las columnas numéricas\n",
    "\n",
    "# Calcula la matriz de correlación\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Encuentra las variables con alta correlación con 'reduction_ins [%]'\n",
    "threshold = 0.2  # Ajusta este valor según tu criterio\n",
    "high_corr_vars = correlation_matrix.index[correlation_matrix['reduction_ins [%]'].abs() > threshold]\n",
    "\n",
    "# Genera el pairplot con las variables seleccionadas\n",
    "sns.pairplot(medium_dcf[high_corr_vars])\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que se crearon características temporales, podemos eliminar la columna `datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna 'datetime' del DataFrame\n",
    "low_dcf = low_dcf.drop(columns=['datetime', 'charge_level'], errors='ignore')\n",
    "medium_dcf = medium_dcf.drop(columns=['datetime', 'charge_level'], errors='ignore')\n",
    "high_dcf = high_dcf.drop(columns=['datetime', 'charge_level'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información estadística general\n",
    "medium_dcf.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos una matriz de correlación y la visualizamos como mapa de calor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1K7Hmk2HzCvi",
    "outputId": "c86739bb-d228-46ae-8b50-10b0100524e0"
   },
   "outputs": [],
   "source": [
    "# Hagamos un HeatMap del df\n",
    "correlacion = low_dcf.corr(method=\"pearson\")\n",
    "fig_heatmap = px.imshow(correlacion,\n",
    "                        text_auto=True,\n",
    "                        title='Heatmap for the Dataset')\n",
    "fig_heatmap.update_layout(width=1400, height=1200, title_font_size=20)\n",
    "fig_heatmap.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación\n",
    "low_mat = low_dcf.corr(method=\"pearson\")\n",
    "\n",
    "# Seleccionar solo la columna 'reduction_ins [%]'\n",
    "low_mat_reduction_ins = low_mat[['reduction_ins [%]']].drop(index='reduction_ins [%]')\n",
    "\n",
    "# Crear el heatmap\n",
    "plt.figure(figsize=(6, 10))  # Ajustar el tamaño del gráfico\n",
    "sns.heatmap(low_mat_reduction_ins, \n",
    "            annot=True,      # Mostrar valores en las celdas\n",
    "            cmap='coolwarm', # Elegir el esquema de colores\n",
    "            fmt='.2f',       # Formato de los números\n",
    "            cbar=True,       # Mostrar barra de color\n",
    "            linewidths=0.5)  # Separación entre celdas\n",
    "\n",
    "# Configurar el título\n",
    "plt.title('Correlation Heatmap reduction_ins[%] for Low Charge', fontsize=16)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hagamos un HeatMap del df\n",
    "correlacion = medium_dcf.corr(method=\"pearson\")\n",
    "fig_heatmap = px.imshow(correlacion,\n",
    "                        text_auto=True,\n",
    "                        title='Heatmap for the Dataset')\n",
    "fig_heatmap.update_layout(width=1400, height=1200, title_font_size=20)\n",
    "fig_heatmap.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación\n",
    "medium_mat = medium_dcf.corr(method=\"pearson\")\n",
    "\n",
    "# Seleccionar solo la columna 'reduction_ins [%]'\n",
    "medium_mat_reduction_ins = medium_mat[['reduction_ins [%]']].drop(index='reduction_ins [%]')\n",
    "\n",
    "# Crear el heatmap\n",
    "plt.figure(figsize=(6, 10))  # Ajustar el tamaño del gráfico\n",
    "sns.heatmap(medium_mat_reduction_ins, \n",
    "            annot=True,      # Mostrar valores en las celdas\n",
    "            cmap='coolwarm', # Elegir el esquema de colores\n",
    "            fmt='.2f',       # Formato de los números\n",
    "            cbar=True,       # Mostrar barra de color\n",
    "            linewidths=0.5)  # Separación entre celdas\n",
    "\n",
    "# Configurar el título\n",
    "plt.title('Correlation Heatmap reduction_ins[%] for Medium Charge', fontsize=16)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hagamos un HeatMap del df\n",
    "correlacion = high_dcf.corr(method=\"pearson\")\n",
    "fig_heatmap = px.imshow(correlacion,\n",
    "                        text_auto=True,\n",
    "                        title='Heatmap for the Dataset')\n",
    "fig_heatmap.update_layout(width=1400, height=1200, title_font_size=20)\n",
    "fig_heatmap.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación\n",
    "high_mat = high_dcf.corr(method=\"pearson\")\n",
    "\n",
    "# Seleccionar solo la columna 'reduction_ins [%]'\n",
    "high_mat_reduction_ins = high_mat[['reduction_ins [%]']].drop(index='reduction_ins [%]')\n",
    "\n",
    "# Crear el heatmap\n",
    "plt.figure(figsize=(6, 10))  # Ajustar el tamaño del gráfico\n",
    "sns.heatmap(high_mat_reduction_ins, \n",
    "            annot=True,      # Mostrar valores en las celdas\n",
    "            cmap='coolwarm', # Elegir el esquema de colores\n",
    "            fmt='.2f',       # Formato de los números\n",
    "            cbar=True,       # Mostrar barra de color\n",
    "            linewidths=0.5)  # Separación entre celdas\n",
    "\n",
    "# Configurar el título\n",
    "plt.title('Correlation Heatmap reduction_ins[%] for High Charge', fontsize=16)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar las matrices de correlación\n",
    "low_mat_reduction_ins['Charge_Level'] = 'Low'\n",
    "medium_mat_reduction_ins['Charge_Level'] = 'Medium'\n",
    "high_mat_reduction_ins['Charge_Level'] = 'High'\n",
    "\n",
    "# Combinar todas las matrices en un solo DataFrame\n",
    "combined_mat = pd.concat([low_mat_reduction_ins, medium_mat_reduction_ins, high_mat_reduction_ins])\n",
    "\n",
    "# Ajustar el índice para un formato más claro\n",
    "combined_mat = combined_mat.reset_index().rename(columns={'index': 'Variable'})\n",
    "\n",
    "# Crear un heatmap agrupado por nivel de carga\n",
    "plt.figure(figsize=(10, 15))\n",
    "heatmap_data = combined_mat.pivot(index='Variable', columns='Charge_Level', values='reduction_ins [%]')\n",
    "sns.heatmap(heatmap_data, \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            fmt='.2f', \n",
    "            linewidths=0.5, \n",
    "            cbar=True)\n",
    "\n",
    "# Configurar el título\n",
    "plt.title('Combined Correlation Heatmap for reduction_ins [%]', fontsize=16)\n",
    "plt.xlabel('Charge Level')\n",
    "plt.ylabel('Variable')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que la matriz es muy amplia, acotamos la selección considerando las características mas importantes para la reducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "rF8N2CTp5eb9",
    "outputId": "8ee6c798-526a-47c8-88d6-6a36039f52ad"
   },
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación solo para 'reduction_lab [%]'\n",
    "correlacion_reduction_ins = medium_dcf.corr(method=\"pearson\")['reduction_ins [%]'].sort_values(ascending=False)\n",
    "\n",
    "# Convertir las correlaciones a un DataFrame para mejor control\n",
    "correlation_df = correlacion_reduction_ins.drop(index='reduction_ins [%]').reset_index()\n",
    "correlation_df.columns = ['Variable', 'Correlation']\n",
    "\n",
    "# Crear un heatmap utilizando Plotly Express\n",
    "fig_heatmap = px.bar(correlation_df,\n",
    "                     x='Correlation',\n",
    "                     y='Variable',\n",
    "                     orientation='h',\n",
    "                     title='Correlation Heatmap for reduction_ins [%]',\n",
    "                     text='Correlation',\n",
    "                     color='Correlation',\n",
    "                     color_continuous_scale='RdBu')  # Escala de colores: rojo para negativos, azul para positivos\n",
    "\n",
    "# Mejorar la estética del gráfico\n",
    "fig_heatmap.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
    "fig_heatmap.update_layout(width=1000,\n",
    "                          height=800,\n",
    "                          title_font_size=20,\n",
    "                          yaxis=dict(title='Variables'),\n",
    "                          xaxis=dict(title='Correlation'))\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig_heatmap.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Variables Clave para el Modelo__:\n",
    "\n",
    "- Las variables más relevantes por su correlación son `sulfidez_ins [%]`, `Temperatura LN a boquillas [°C]`, `Secundario Alto`, y `Solidos a quemado [%]`. Estas deben ser prioritarias en el desarrollo del modelo predictivo.\n",
    "\n",
    "2. __Investigaciones Adicionales__:\n",
    "\n",
    "- Explorar las razones detrás de la correlación negativa de `SO2 [mg/Nm³]` y `Temperatura de salida vapor [°C]` para identificar posibles ajustes operativos.\n",
    "\n",
    "- Analizar el impacto estacional reflejado en la correlación positiva de `month` para ajustar estrategias en función del tiempo.\n",
    "\n",
    "3. __Optimización del Proceso__:\n",
    "\n",
    "- Aumentar la atención en las condiciones operativas relacionadas con la `sulfidez_ins [%]` y `Temperatura LN a boquillas [°C]`, ya que estas parecen tener un impacto significativo en el desempeño del proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhU_oYDbPNUa"
   },
   "outputs": [],
   "source": [
    "# Definir la variable objetivo y sus características\n",
    "X = medium_dcf.drop('reduction_ins [%]', axis=1)\n",
    "y = medium_dcf['reduction_ins [%]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar un modelo predictivo para la variable de `reducción` de la caldera segmentaremos la base de datos en 3 conjuntos, `entrenamiento`, `test` y `validación`. Los datos de validación permitiran que podamos testear modelos con data nueva o que no ha sido utilizada previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcaKIDM5PNUa"
   },
   "outputs": [],
   "source": [
    "# Primera división: dividir en conjunto de entrenamiento (80%) y conjunto de prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Segunda división: dividir el conjunto de entrenamiento en entrenamiento (90% de 80%) y validación (10% de 80%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\n",
    "\n",
    "# Tamaños resultantes\n",
    "print(f\"Tamaño de X_train: {X_train.shape}\")\n",
    "print(f\"Tamaño de X_val: {X_val.shape}\")\n",
    "print(f\"Tamaño de X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazamos valores `inf` por valores nulos y eliminamos columnas que excedan un 50% de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v_4NlIfPNUb"
   },
   "outputs": [],
   "source": [
    "# Reemplazar inf con NaN en X_train, X_test y X_val\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "X_val = X_val.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Eliminar columnas con más del 50% de NaNs\n",
    "X_train = X_train.dropna(thresh=X_train.shape[0] * 0.5, axis=1)\n",
    "X_test = X_test.dropna(thresh=X_test.shape[0] * 0.5, axis=1)\n",
    "X_val = X_val.dropna(thresh=X_val.shape[0] * 0.5, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego imputamos las columnas con el promedio para cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFJs9F86zCvj"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Crear el imputador para llenar valores faltantes con la media de cada columna\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Ajustar el imputador solo con los datos de entrenamiento\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "# Transformar el conjunto de validación y prueba usando el imputador ajustado\n",
    "X_val = imputer.transform(X_val)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamos las características con objetivo de normalizar sus datos y mantenerlas en un rango comparativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9L9TVFBPNUb"
   },
   "outputs": [],
   "source": [
    "# Crear el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar el escalador solo con los datos de entrenamiento\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformar el conjunto de validación y prueba usando el escalador ajustado\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenaremos diferentes modelos de machine learning para evaluar cual obtiene las mejores metricas, que permitan reducir el error en la instrumentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQ1-Fd3894KX"
   },
   "outputs": [],
   "source": [
    "# Diccionario de modelos\n",
    "modelos = {\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'LightGBM': LGBMRegressor(),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "# Diccionario de hiperparámetros para búsqueda\n",
    "parametros = {\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [5, 10, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [30, 50, 100],\n",
    "        'max_depth': [5, 10, None],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'n_estimators': [30, 50, 100],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': [30, 50, 100],\n",
    "        'max_depth': [5, 10, 20],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'num_leaves': [20, 31, 40]\n",
    "    },\n",
    "    'SVR': {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'kernel': ['rbf', 'linear'],\n",
    "                'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideraremos las siguientes metricas, `Mean Absolute Error (MAE)`, `Mean Square Error (MSE)`, `Root Mean Square Error (RMSE)` y el `Coeficiente de Determinación`($R^2$). Luego creamos una función que evalua cada modelo considerando la grilla de hiperparametros definidos en la funcion de entrenamiento y considera los mejores parametros para evaluar las metricas y su tiempo de entrenamiento y evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "q8FJzxYb94KX",
    "outputId": "d20ea3ec-dcc8-4a4c-de7c-5de9cde0b21a"
   },
   "outputs": [],
   "source": [
    "# Diccionario para almacenar los resultados\n",
    "resultados = {\n",
    "    'Modelo': [],\n",
    "    'Mejores Hiperparámetros': [],\n",
    "    'MAE (Validación)': [],\n",
    "    'MSE (Validación)': [],\n",
    "    'RMSE (Validación)': [],\n",
    "    'R2 (Validación)': [],\n",
    "    'MAE (Prueba)': [],\n",
    "    'MSE (Prueba)': [],\n",
    "    'RMSE (Prueba)': [],\n",
    "    'R2 (Prueba)': [],\n",
    "    'Tiempo de Entrenamiento y Evaluación (s)': []\n",
    "}\n",
    "\n",
    "# Evaluar modelos con los mejores hiperparámetros\n",
    "for nombre, modelo in modelos.items():\n",
    "    try:\n",
    "        # Iniciar el cronómetro para medir el tiempo de entrenamiento y evaluación\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        if parametros.get(nombre):  # Si hay hiperparámetros para ajustar\n",
    "            search = GridSearchCV(\n",
    "                modelo,\n",
    "                parametros[nombre],\n",
    "                cv=3,\n",
    "                scoring='neg_mean_squared_error',\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            # Ajustar el modelo\n",
    "            search.fit(X_train, y_train)\n",
    "\n",
    "            best_model = search.best_estimator_\n",
    "            best_params = search.best_params_\n",
    "        else:\n",
    "            # Si no hay hiperparámetros, usar el modelo tal cual\n",
    "            best_model = modelo\n",
    "            best_model.fit(X_train, y_train)\n",
    "            best_params = \"No aplica\"\n",
    "\n",
    "        # Realizar predicciones en el conjunto de validación\n",
    "        y_pred_val = best_model.predict(X_val)\n",
    "\n",
    "        # Calcular métricas en el conjunto de validación\n",
    "        mae_val = round(mean_absolute_error(y_val, y_pred_val), 4)\n",
    "        mse_val = round(mean_squared_error(y_val, y_pred_val), 4)\n",
    "        rmse_val = round(np.sqrt(mse_val), 4)\n",
    "        r2_val = round(r2_score(y_val, y_pred_val), 4)\n",
    "\n",
    "        # Realizar predicciones en el conjunto de prueba (solo al final)\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        # Calcular métricas en el conjunto de prueba\n",
    "        mae_test = round(mean_absolute_error(y_test, y_pred_test), 4)\n",
    "        mse_test = round(mean_squared_error(y_test, y_pred_test), 4)\n",
    "        rmse_test = round(np.sqrt(mse_test), 4)\n",
    "        r2_test = round(r2_score(y_test, y_pred_test), 4)\n",
    "\n",
    "        # Calcular el tiempo de entrenamiento y evaluación\n",
    "        execution_time = round(time.perf_counter() - start_time, 4)\n",
    "\n",
    "        # Guardar los resultados en el diccionario\n",
    "        resultados['Modelo'].append(nombre)\n",
    "        resultados['Mejores Hiperparámetros'].append(best_params)\n",
    "        resultados['MAE (Validación)'].append(mae_val)\n",
    "        resultados['MSE (Validación)'].append(mse_val)\n",
    "        resultados['RMSE (Validación)'].append(rmse_val)\n",
    "        resultados['R2 (Validación)'].append(r2_val)\n",
    "        resultados['MAE (Prueba)'].append(mae_test)\n",
    "        resultados['MSE (Prueba)'].append(mse_test)\n",
    "        resultados['RMSE (Prueba)'].append(rmse_test)\n",
    "        resultados['R2 (Prueba)'].append(r2_test)\n",
    "        resultados['Tiempo de Entrenamiento y Evaluación (s)'].append(execution_time)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluando el modelo {nombre}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6B1ddQ1PNUb",
    "outputId": "41f7837b-4d2f-4a94-8b51-14925b3dcb21"
   },
   "outputs": [],
   "source": [
    "# Convertir los resultados en un DataFrame\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Mostrar la tabla de resultados\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusión**\n",
    "\n",
    "El análisis comparativo de los modelos demuestra que el desempeño varía significativamente en términos de precisión \\( $R^2$ \\) y tiempo de entrenamiento. Entre todos los modelos evaluados:\n",
    "\n",
    "- **Random Forest** ofrece el mejor rendimiento con un \\( $R^2$ = 0.975 \\) en el conjunto de prueba, lo que indica una excelente capacidad de generalización. Sin embargo, su tiempo de entrenamiento es considerablemente alto (6302s).\n",
    "\n",
    "- **GradientBoostingRegressor** se posiciona como una opción balanceada, logrando un \\( $R^2$ = 0.936 \\) en prueba y un tiempo de entrenamiento moderado (966s), siendo adecuado para escenarios donde se necesita precisión con un tiempo de entrenamiento razonable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definido el modelo con mejores metricas, aplicamos `Randomized Search` considerando mas posibilidades de mejorar las metricas obtenidas previamente aumentando las estimaciones, profundidad, numero minimo de muestras, cantidad de caracteristicas y bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Definir una grilla más amplia para RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Instanciar Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV para ajuste\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Ajustar el modelo usando el conjunto de entrenamiento\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "print(\"Mejores Hiperparámetros:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q657YYmIzCvk",
    "outputId": "1d2519ac-8f5d-4915-a1d0-955a610fc454"
   },
   "outputs": [],
   "source": [
    "# Define el modelo con los mejores hiperparámetros\n",
    "best_model = RandomForestRegressor(max_depth = 20, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 100, random_state=42)\n",
    "\n",
    "# Entrena el modelo usando el conjunto de entrenamiento\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realiza predicciones en el conjunto de validación\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "\n",
    "# Realiza predicciones en el conjunto de prueba\n",
    "y_pred_test = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula las métricas de evaluación en el conjunto de validación\n",
    "mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "rmse_val = np.sqrt(mse_val)\n",
    "r2_val = r2_score(y_val, y_pred_val)\n",
    "\n",
    "# Calcula las métricas de evaluación en el conjunto de prueba\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Imprime las métricas para el conjunto de validación\n",
    "print(\"Conjunto de Validación:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_val:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_val:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_val:.4f}\")\n",
    "print(f\"R-squared (R2): {r2_val:.4f}\")\n",
    "\n",
    "# Imprime las métricas para el conjunto de prueba\n",
    "print(\"\\nConjunto de Prueba:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_test:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_test:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_test:.4f}\")\n",
    "print(f\"R-squared (R2): {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizaremos las características mas importantes para a futuro reducir la cardinalidad del problema y asi obtener buenas métricas en un menor tiempo de entrenamiento y evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los nombres de las características desde el DataFrame\n",
    "feature_names = X.columns if hasattr(X, 'columns') else [f'Feature {i}' for i in range(X.shape[1])]\n",
    "\n",
    "# Obtener la importancia de los atributos\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Crear un DataFrame para ordenar y visualizar la importancia, seleccionando solo las X más importantes\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False).head(5)\n",
    "\n",
    "# Visualizar la importancia de los X atributos principales usando Plotly\n",
    "fig = px.bar(\n",
    "    feature_importance_df.sort_values(by='Importance', ascending=True),  # Orden ascendente para gráfico horizontal\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    orientation='h',  # Gráfico horizontal\n",
    "    title='Top 5 Atributos Más Importantes',\n",
    "    labels={'Importance': 'Importancia', 'Feature': 'Atributo'},\n",
    "    text='Importance',  # Mostrar los valores en las barras\n",
    "    color='Importance',  # Aplicar degradado basado en la importancia\n",
    "    color_continuous_scale='Viridis'  # Escala de colores degradada\n",
    ")\n",
    "\n",
    "# Ajustar la apariencia\n",
    "fig.update_layout(\n",
    "    template='plotly_white',\n",
    "    xaxis_title='Importancia',\n",
    "    yaxis_title='Atributo',\n",
    "    coloraxis_showscale=True  # Mostrar la barra de escala de colores\n",
    ")\n",
    "fig.update_traces(texttemplate='%{text:.4f}', textposition='outside')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "- `La sulfidez_ins [%]` sigue siendo el factor más determinante, lo que confirma que el monitoreo y ajuste de este parámetro es esencial para optimizar el rendimiento del proceso.\n",
    "\n",
    "- Las variables temporales (`month` y `day`) reflejan posibles patrones estacionales y operativos que deben ser investigados para mejorar la estabilidad del sistema.\n",
    "\n",
    "- Parámetros físicos como la `Temperatura LN a boquillas [°C]` y el `O2_cont_center [%]` también tienen un impacto significativo en el rendimiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaremos la relación de las variables mas importantes segun el modelo predictivo en comparación con la reducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Crear subplots con 3 filas y 2 columnas (suficientes para 5 gráficos)\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2, \n",
    "    subplot_titles=[\n",
    "        \"Sulfidez_ins [%] vs Reduction_ins [%]\", \n",
    "        \"Month vs Reduction_ins [%]\", \n",
    "        \"Alcali_lv_ins [g/L] vs Reduction_ins [%]\",\n",
    "        \"Temperatura LN a boquillas [°C] vs Reduction_ins [%]\",\n",
    "        \"Day vs Reduction_ins [%]\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_filtered['sulfidez_ins [%]'],  # Cambia al nombre correcto\n",
    "        y=df_filtered['reduction_ins [%]'],\n",
    "        mode='markers',\n",
    "        name='Sulfidez_ins [%]'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Gráfico 2: Month\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_filtered['month'],\n",
    "        y=df_filtered['reduction_ins [%]'],\n",
    "        mode='markers',\n",
    "        name='Month'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Gráfico 3: Alcali_lv_ins [g/L]\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_filtered['alcali_lv_ins [g/L]'],\n",
    "        y=df_filtered['reduction_ins [%]'],\n",
    "        mode='markers',\n",
    "        name='Alcali_lv_ins [g/L]'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Gráfico 4: Temperatura LN a boquillas [°C]\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_filtered['Temperatura LN a boquillas [°C]'],\n",
    "        y=df_filtered['reduction_ins [%]'],\n",
    "        mode='markers',\n",
    "        name='Temperatura LN a boquillas [°C]'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Gráfico 5: Day\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_filtered['day'],\n",
    "        y=df_filtered['reduction_ins [%]'],\n",
    "        mode='markers',\n",
    "        name='Day'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Configuración general\n",
    "fig.update_layout(\n",
    "    title=\"Gráficos de Dispersión: Variables vs Reduction_ins [%]\",\n",
    "    height=900,  # Altura total\n",
    "    width=1000,  # Ancho total\n",
    "    showlegend=False  # Ocultar leyendas individuales\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `Sulfidez`:\n",
    "\n",
    "Monitorear y mantener valores de sulfidez_ins [%] por encima de 20% para mejorar la eficiencia del proceso.\n",
    "Analizar los factores que contribuyen a valores bajos de sulfidez.\n",
    "\n",
    "2. `Alcali_lv_ins [g/L]`:\n",
    "\n",
    "Mantener los niveles de álcali en el rango de 160-180 g/L para reducir la variabilidad en el rendimiento.\n",
    "\n",
    "3. `Temperatura LN a boquillas`:\n",
    "\n",
    "Asegurar un control preciso de la temperatura del licor negro en las boquillas, idealmente entre 138°C y 140°C.\n",
    "\n",
    "4. `Análisis Temporal`:\n",
    "\n",
    "Investigar las variaciones diarias y estacionales para identificar factores externos o internos que puedan influir en la eficiencia del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar valores reales vs predicciones para el conjunto de validación\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(y_val)), y_val, label='Valores Reales (Validación)', linestyle='-', color='blue')\n",
    "plt.plot(range(len(y_pred_val)), y_pred_val, label='Predicciones (Validación)', linestyle='-', color='red')\n",
    "plt.title('Valores Reales vs Predicciones (Validación)', fontsize=16)\n",
    "plt.xlabel('Índice', fontsize=12)\n",
    "plt.ylabel('Variable Objetivo', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar valores reales vs predicciones para el conjunto de prueba\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(y_test)), y_test, label='Valores Reales (Prueba)', linestyle='-', color='blue')\n",
    "plt.plot(range(len(y_pred_test)), y_pred_test, label='Predicciones (Prueba)', linestyle='--', color='orange')\n",
    "plt.title('Valores Reales vs Predicciones (Prueba)', fontsize=16)\n",
    "plt.xlabel('Índice', fontsize=12)\n",
    "plt.ylabel('Variable Objetivo', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Datos para el conjunto de validacion\n",
    "x_val = np.arange(len(y_val))\n",
    "y_val = y_val\n",
    "y_pred_val = y_pred_val\n",
    "\n",
    "# Datos para el conjunto de prueba\n",
    "x_test = np.arange(len(y_test))\n",
    "y_test = y_test\n",
    "y_pred_test = y_pred_test\n",
    "\n",
    "# Crear gráfico para el conjunto de validacion\n",
    "fig_val = go.Figure()\n",
    "fig_val.add_trace(go.Scatter(x=x_val, y=y_val, mode='lines', name ='Valores Reales (Validación)'))\n",
    "fig_val.add_trace(go.Scatter(x=x_val, y=y_pred_val, mode='lines', name ='Valores Predichos (Validación)'))\n",
    "\n",
    "# Añade título y etiquetas\n",
    "fig_val.update_layout(\n",
    "    title = 'Valores Reales vs Predichos - Conjunto de Validación',\n",
    "    xaxis_title = 'Índice',\n",
    "    yaxis_title = 'Valores',\n",
    "    legend = dict(x=0.01, y=0.99),\n",
    ")\n",
    "\n",
    "# Crea gráfico para el conjunto de prueba\n",
    "fig_test = go.Figure()\n",
    "fig_test.add_trace(go.Scatter(x=x_test, y=y_test, mode='lines', name ='Valores Reales (Prueba)'))\n",
    "fig_test.add_trace(go.Scatter(x=x_test, y=y_pred_test, mode='lines', name ='Valores Predichos (Prueba)'))\n",
    "\n",
    "# Añade título y etiquetas\n",
    "fig_val.update_layout(\n",
    "    title = 'Valores Reales vs Predichos - Conjunto de Prueba',\n",
    "    xaxis_title = 'Índice',\n",
    "    yaxis_title = 'Valores',\n",
    "    legend = dict(x=0.01, y=0.99),\n",
    ")\n",
    "\n",
    "# Muestra las graficas\n",
    "fig_val.show()\n",
    "fig_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados de Modelos de Machine Learning y Variables Clave\n",
    "\n",
    "## **Resultados de los Modelos de Machine Learning**\n",
    "\n",
    "1. **Random Forest**:\n",
    "\n",
    "   - Ofreció el mejor desempeño predictivo (\\(R^2 = 0.978\\)) en el conjunto de prueba, demostrando una alta capacidad de generalización para predecir el porcentaje de reducción.\n",
    "   - Su tiempo de entrenamiento elevado (2014 segundos) lo hace menos eficiente para escenarios donde la velocidad es crítica.\n",
    "\n",
    "2. **GradientBoostingRegressor**:\n",
    "\n",
    "   - Presentó un balance entre precisión (\\(R^2 = 0.936\\)) y tiempo de entrenamiento (642 segundos), siendo adecuado para aplicaciones prácticas donde se necesita un equilibrio entre rendimiento y eficiencia.\n",
    "\n",
    "3. **Decision Tree**:\n",
    "\n",
    "   - Aunque menos preciso (\\(R^2 = 0.933\\)) que los modelos más complejos, destaca por su velocidad de entrenamiento (27 segundos), siendo una opción eficiente en entornos con limitaciones de tiempo.\n",
    "\n",
    "4. **Importancia General**:\n",
    "\n",
    "   - Los modelos confirman que existen relaciones no lineales entre las variables predictoras y el **% de reducción**, lo que justifica el uso de algoritmos avanzados en lugar de enfoques lineales.\n",
    "\n",
    "---\n",
    "\n",
    "## **Variables Clave para el Modelo**\n",
    "\n",
    "1. **Sulfidez_ins [%]**:\n",
    "\n",
    "   - La variable más importante, confirmada por su alta correlación y relevancia en los modelos. Valores superiores a 20% son esenciales para mantener la eficiencia de reducción.\n",
    "\n",
    "2. **month** y **day**:\n",
    "\n",
    "   - Estas variables temporales sugieren patrones estacionales y cíclicos que influyen en el rendimiento del sistema. Esto puede estar relacionado con condiciones operativas o cambios externos.\n",
    "\n",
    "3. **Alcali_lv_ins [g/L]**:\n",
    "\n",
    "   - Valores dentro del rango óptimo (160-180 g/L) están asociados con mayor estabilidad en el proceso, mientras que valores fuera de este rango pueden causar fluctuaciones.\n",
    "\n",
    "4. **Temperatura LN a boquillas [°C]**:\n",
    "\n",
    "   - Un control preciso en el rango de 138-140°C contribuye a una combustión más eficiente y a un mejor rendimiento del sistema.\n",
    "\n",
    "5. **O2_cont_center [%]**:\n",
    "\n",
    "   - La concentración de oxígeno en el centro de la caldera es un indicador clave del equilibrio de combustión, afectando directamente la eficiencia del proceso.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusiones Operativas**\n",
    "\n",
    "1. **Eficiencia del Modelo**:\n",
    "\n",
    "   - Los resultados demuestran que modelos avanzados como `Random Forest` son capaces de capturar relaciones complejas entre las variables, siendo altamente efectivos para predecir el **% de reducción**.\n",
    "\n",
    "2. **Factores Químicos y Operativos**:\n",
    "\n",
    "   - La química del proceso, representada por **sulfidez_ins [%]** y **alcali_lv_ins [g/L]**, es determinante para optimizar la recuperación química en la caldera.\n",
    "   - Los parámetros físicos, como la **Temperatura LN a boquillas [°C]** y el oxígeno, son igualmente relevantes para mantener un rendimiento consistente.\n",
    "\n",
    "3. **Patrones Temporales**:\n",
    "\n",
    "   - Los modelos destacan la importancia de analizar patrones estacionales y cíclicos (por ejemplo, **month** y **day**) para ajustar las condiciones operativas y minimizar fluctuaciones.\n",
    "\n",
    "---\n",
    "\n",
    "## **Recomendaciones Finales**\n",
    "\n",
    "1. **Monitoreo en Tiempo Real**:\n",
    "\n",
    "   - Implementar sensores y sistemas de control para monitorear y ajustar en tiempo real variables como **sulfidez_ins [%]**, **alcali_lv_ins [g/L]**, y **Temperatura LN a boquillas [°C]**.\n",
    "\n",
    "2. **Optimización Basada en Modelos**:\n",
    "\n",
    "   - Utilizar Random Forest o Gradient Boosting como herramientas principales para predecir y optimizar el rendimiento de la caldera recuperadora.\n",
    "\n",
    "3. **Análisis Temporal**:\n",
    "\n",
    "   - Explorar más a fondo los patrones temporales y ajustar las operaciones de la planta en función de ciclos estacionales o diarios identificados por las variables **month** y **day**.\n",
    "\n",
    "4. **Pruebas de Escenarios**:\n",
    "\n",
    "   - Realizar simulaciones ajustando variables clave para evaluar su impacto en el **% de reducción** y establecer condiciones óptimas de operación.\n",
    "\n",
    "Con estas estrategias, será posible mejorar significativamente la eficiencia operativa, reducir costos y mantener un proceso sostenible y de alto rendimiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
